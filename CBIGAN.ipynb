{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# installation\n",
    "!pip install pandas\n",
    "!pip install torchinfo\n",
    "!pip install tqdm\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!curl -L -u $username:$token\\\n",
    "  -o benign-dataset.zip\\\n",
    "  https://www.kaggle.com/api/v1/datasets/download/aquacoder/benign-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p dataset\n",
    "!unzip -q benign-dataset.zip -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloaders(image_size, batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)) # Scales to [-1, 1] for Tanh\n",
    "    ])\n",
    "\n",
    "    # Train: Expects ./train/some_class/image.png\n",
    "    train_dataset = datasets.ImageFolder(root='./dataset/train', transform=transform)\n",
    "\n",
    "    if 'benign' in train_dataset.classes:\n",
    "        benign_class_idx = train_dataset.class_to_idx['benign']\n",
    "        \n",
    "        # Filter samples to include only those belonging to the 'benign' class\n",
    "        train_dataset.samples = [\n",
    "            (path, label) for path, label in train_dataset.samples\n",
    "            if label == benign_class_idx\n",
    "        ]\n",
    "        # The new class list for the train set is now just ['benign']\n",
    "        print(f\"Training on {len(train_dataset.samples)} samples from the 'benign' class.\")\n",
    "    else:\n",
    "        # If 'benign' is not found, the FileNotFoundError was probably correct.\n",
    "        raise FileNotFoundError(f\"Could not find the expected 'benign' class folder inside {train_root_path}\")\n",
    "    \n",
    "    # Test: Expects ./test/benign/ and ./test/malware/\n",
    "    test_dataset = datasets.ImageFolder(root='./dataset/test', transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, test_loader, test_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "\n",
    "def l1(x, y):\n",
    "    \"\"\"\n",
    "    Computes L1 distance keeping batch dimension.\n",
    "    \"\"\"\n",
    "    x = x.view(x.size(0), -1)\n",
    "    y = y.view(y.size(0), -1)\n",
    "    return torch.sum(torch.abs(x - y), dim=1)\n",
    "\n",
    "def gradient_penalty(discriminator, x, x_gen, z, z_gen, device):\n",
    "    \"\"\"\n",
    "    Calculates the WGAN-GP gradient penalty.\n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    alpha = torch.rand(batch_size, 1, device=device)\n",
    "    alpha_img = alpha.view(batch_size, 1, 1, 1) \n",
    "    alpha_z = alpha.view(batch_size, 1)\n",
    "\n",
    "    x_hat = (alpha_img * x + (1 - alpha_img) * x_gen).detach().requires_grad_(True)\n",
    "    z_hat = (alpha_z * z + (1 - alpha_z) * z_gen).detach().requires_grad_(True)\n",
    "    score_hat = discriminator(x_hat, z_hat)\n",
    "\n",
    "    gradients = autograd.grad(\n",
    "        outputs=score_hat,\n",
    "        inputs=[x_hat, z_hat],\n",
    "        grad_outputs=torch.ones_like(score_hat),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )\n",
    "    \n",
    "    dx, dz = gradients\n",
    "    \n",
    "    dx = dx.view(dx.size(0), -1)\n",
    "    dz = dz.view(dz.size(0), -1)\n",
    "    \n",
    "    grads = torch.cat([dx, dz], dim=1)\n",
    "    grads_norm = torch.sqrt(torch.sum(grads ** 2, dim=1) + 1e-12)    \n",
    "    norm_penalty = (grads_norm - 1) ** 2\n",
    "    return norm_penalty.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "def get_bn_layer(bn_type='none', num_features=None, dims=None):\n",
    "    if bn_type == 'batch':\n",
    "        return nn.BatchNorm1d(num_features) if dims == 1 else nn.BatchNorm2d(num_features)\n",
    "    elif bn_type == 'layer':\n",
    "        return nn.GroupNorm(1, num_features)\n",
    "    elif bn_type == 'instance':\n",
    "        return nn.InstanceNorm1d(num_features) if dims == 1 else nn.InstanceNorm2d(num_features, affine=True)\n",
    "    elif bn_type == 'none':\n",
    "        return nn.Identity()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported normalization layer type: {bn_type}\")\n",
    "\n",
    "class GBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upsample=True, upsample_type='bilinear', use_bias=True, bn_type='none', act=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        \n",
    "        if upsample:\n",
    "            if upsample_type == 'bilinear':\n",
    "                self.upsample_layer = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            else:\n",
    "                self.upsample_layer = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=use_bias)\n",
    "        self.bn1 = get_bn_layer(bn_type, out_channels)\n",
    "        self.act1 = act()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=use_bias)\n",
    "        self.bn2 = get_bn_layer(bn_type, out_channels)\n",
    "        self.act2 = act()\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0)\n",
    "        \n",
    "        self.conv_skip = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=use_bias)\n",
    "        self.bn_skip = get_bn_layer(bn_type, out_channels)\n",
    "        \n",
    "        self.bn_final = get_bn_layer(bn_type, out_channels)\n",
    "        self.act_final = act()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = self.upsample_layer(x)\n",
    "            \n",
    "        skip = self.bn_skip(self.conv_skip(x))\n",
    "        h = self.act1(self.bn1(self.conv1(x)))\n",
    "        h = self.act2(self.bn2(self.conv2(h)))\n",
    "        h = self.conv3(h)\n",
    "        \n",
    "        return self.act_final(self.bn_final(h + skip))\n",
    "\n",
    "#DBlock(3, 1 * channels, use_bias=use_bias, bn_type=bn_type, act=act),        # -> 64x64 if image_size=128\n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pool=True, use_bias=True, bn_type='none', act=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=use_bias)\n",
    "        self.bn1 = get_bn_layer(bn_type, out_channels)\n",
    "        self.act1 = act()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=use_bias)\n",
    "        self.bn2 = get_bn_layer(bn_type, out_channels)\n",
    "        self.act2 = act()\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0)\n",
    "\n",
    "        self.conv_skip = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=use_bias)\n",
    "        self.bn_skip = get_bn_layer(bn_type, out_channels)\n",
    "\n",
    "        self.bn_final = get_bn_layer(bn_type, out_channels)\n",
    "        self.act_final = act()\n",
    "        \n",
    "        if self.pool:\n",
    "            self.pool_layer = nn.AvgPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip = self.bn_skip(self.conv_skip(x))\n",
    "        \n",
    "        h = self.act1(self.bn1(self.conv1(x)))\n",
    "        h = self.act2(self.bn2(self.conv2(h)))\n",
    "        h = self.conv3(h)\n",
    "        \n",
    "        out = self.act_final(self.bn_final(h + skip))\n",
    "        if self.pool:\n",
    "            out = self.pool_layer(out)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size, channels=3, upsample_first=True, upsample_type='bilinear', bn_type='none', act_type='lrelu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        use_bias = bn_type == 'none'\n",
    "        act = lambda: nn.LeakyReLU(0.2, inplace=True) if act_type == 'lrelu' else nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.init_dense = nn.Linear(latent_size, 2 * 2 * 32 * channels, bias=use_bias)\n",
    "        self.init_bn = get_bn_layer(bn_type, num_features=2 * 2 * 32 * channels, dims=1)\n",
    "        self.init_channels = 32 * channels\n",
    "        \n",
    "        self.g_block1 = GBlock(32 * channels, 32 * channels, upsample=upsample_first, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block2 = GBlock(32 * channels, 32 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block3 = GBlock(32 * channels, 16 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block4 = GBlock(16 * channels, 8 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block5 = GBlock(8 * channels, 4 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block6 = GBlock(4 * channels, 3 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block7 = GBlock(3 * channels, 2 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block8 = GBlock(2 * channels, 1 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "        self.g_block9 = GBlock(1 * channels, 1 * channels, upsample_type=upsample_type, use_bias=use_bias, bn_type=bn_type, act=act)\n",
    "\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(1 * channels, 3, kernel_size=1, padding=0)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_dense(x);\n",
    "        x = self.init_bn(x);\n",
    "        \n",
    "        # Reshape to (Batch, Channels, Height, Width) for PyTorch conv layers\n",
    "        x = x.view(-1, self.init_channels, 2, 2)\n",
    "        x = self.g_block1(x)\n",
    "        x = self.g_block2(x)\n",
    "        x = self.g_block3(x)\n",
    "        x = self.g_block4(x)\n",
    "        x = self.g_block5(x)\n",
    "        x = self.g_block6(x)\n",
    "        x = self.g_block7(x)\n",
    "        x = self.g_block8(x)\n",
    "        x = self.g_block9(x)\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return self.tanh(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, image_size, latent_size, channels=3, bn_type='none', act_type='lrelu'):\n",
    "        super().__init__()\n",
    "        use_bias = bn_type == 'none'\n",
    "        act = lambda: nn.LeakyReLU(0.2, inplace=True) if act_type == 'lrelu' else nn.ReLU(inplace=True)\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            DBlock(3, 1 * channels, use_bias=use_bias, bn_type=bn_type, act=act),        # -> 256x256\n",
    "            DBlock(1 * channels, 2 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 128x128\n",
    "            DBlock(2 * channels, 3 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 64x64\n",
    "            DBlock(3 * channels, 4 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 32x32\n",
    "            DBlock(4 * channels, 8 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 16x16\n",
    "            DBlock(8 * channels, 16 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 8x8\n",
    "            DBlock(16 * channels, 32 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 4x4\n",
    "            DBlock(32 * channels, 32 * channels, pool=False, use_bias=use_bias, bn_type=bn_type, act=act) # -> 4x4\n",
    "        )\n",
    "        \n",
    "        self.final_dense1 = nn.Linear(32 * channels * 4 * 4, 32 * channels * 2 * 2, bias=use_bias)\n",
    "        self.final_bn = get_bn_layer(bn_type, num_features=32 * channels * 2 * 2, dims=1)\n",
    "        self.final_act = act()\n",
    "        self.final_dense2 = nn.Linear(32 * channels * 2 * 2, latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.final_act(self.final_bn(self.final_dense1(x)))\n",
    "        x = self.final_dense2(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, image_size, latent_size, channels=3, bn_type='none', act_type='lrelu'):\n",
    "        super().__init__()\n",
    "        use_bias = bn_type == 'none'\n",
    "        act = lambda: nn.LeakyReLU(0.2, inplace=True) if act_type == 'lrelu' else nn.ReLU(inplace=True)\n",
    "\n",
    "        self.latent_path = nn.Sequential(\n",
    "            nn.Linear(latent_size, 512, bias=use_bias),\n",
    "            get_bn_layer(bn_type, 512, dims=1),\n",
    "            act(),\n",
    "            nn.Linear(512, 512, bias=use_bias),\n",
    "            get_bn_layer(bn_type, 512, dims=1),\n",
    "            act(),\n",
    "            nn.Linear(512, 512, bias=use_bias),\n",
    "            get_bn_layer(bn_type, 512, dims=1),\n",
    "            act()\n",
    "        )\n",
    "        self.image_path = nn.Sequential(\n",
    "            DBlock(3, 1 * channels, use_bias=use_bias, bn_type=bn_type, act=act),        # -> 256x256\n",
    "            DBlock(1 * channels, 2 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 128x128\n",
    "            DBlock(2 * channels, 3 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 64x64\n",
    "            DBlock(3 * channels, 4 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 32x32\n",
    "            DBlock(4 * channels, 8 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 16x16\n",
    "            DBlock(8 * channels, 16 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 8x8\n",
    "            DBlock(16 * channels, 32 * channels, use_bias=use_bias, bn_type=bn_type, act=act), # -> 4x4\n",
    "            DBlock(32 * channels, 32 * channels, pool=False, use_bias=use_bias, bn_type=bn_type, act=act) # -> 4x4\n",
    "        )\n",
    "\n",
    "        # Common path - split into feature extraction and final classification\n",
    "        self.common_path_feature = nn.Sequential(\n",
    "            nn.Linear(32 * channels * 4 * 4 + 512, 32 * channels, bias=use_bias),\n",
    "            get_bn_layer(bn_type, 32 * channels, dims=1),\n",
    "            act()\n",
    "        )\n",
    "        self.common_path_classifier = nn.Linear(32 * channels, 1)\n",
    "\n",
    "    def forward(self, image, latent, return_features=False):\n",
    "        l = self.latent_path(latent)\n",
    "        x = self.image_path(image)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        combined = torch.cat([x, l], dim=1)\n",
    "        features = self.common_path_feature(combined)\n",
    "        \n",
    "        if return_features:\n",
    "            return features\n",
    "        else:\n",
    "            return self.common_path_classifier(features)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "from model import Generator, Encoder, Discriminator\n",
    "from dataset import get_dataloaders\n",
    "from losses import gradient_penalty, compute_l1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "def get_anomaly_score(generator, encoder, discriminator, images, lambda_):\n",
    "    generator.eval()\n",
    "    encoder.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        latent = encoder(images)\n",
    "        reconstructed_img = generator(latent)\n",
    "        \n",
    "        # Features from discriminator (using the return_features flag in your model.py)\n",
    "        feat_real = discriminator(images, latent, return_features=True)\n",
    "        feat_recon = discriminator(reconstructed_img, latent, return_features=True)\n",
    "        \n",
    "        # Loss R (Pixel) and Loss f_D (Feature)\n",
    "        l_r = torch.mean(torch.abs(images - reconstructed_img), dim=[1, 2, 3])\n",
    "        l_fd = torch.mean(torch.abs(feat_real - feat_recon), dim=1)\n",
    "        \n",
    "        score = (1 - lambda_) * l_r + lambda_ * l_fd\n",
    "    return score\n",
    "\n",
    "def save_reconstruction_grid(real_images, netE, netG, epoch, device, save_path=\"reconstructions\"):\n",
    "    \"\"\"\n",
    "    Creates a grid: Top row = Real Images, Bottom row = Reconstructions.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    netE.eval()\n",
    "    netG.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get reconstructions: G(E(x))\n",
    "        recons = netG(netE(real_images[:8])) \n",
    "        real_samples = real_images[:8]\n",
    "        \n",
    "        # Combine into one grid: Normalize from [-1, 1] to [0, 1] for plotting\n",
    "        combined = torch.cat([real_samples, recons], dim=0)\n",
    "        grid = vutils.make_grid(combined, nrow=8, normalize=True, value_range=(-1, 1))\n",
    "        \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(f\"Epoch {epoch} Reconstructions (Top: Real, Bottom: G(E(x)))\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{save_path}/epoch_{epoch}.png\")\n",
    "        plt.close()\n",
    "\n",
    "def plot_loss_curves(history, save_path=\"plots\"):\n",
    "    \"\"\"\n",
    "    Plots the training loss trends for Discriminator and Generator/Encoder.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history['d_loss'], label='D Loss')\n",
    "    plt.plot(history['ge_loss'], label='GE Loss')\n",
    "    plt.xlabel('Iterations (x100)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('CBiGAN Training Losses')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{save_path}/loss_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(netG, netE, netD, test_loader, device, lambda_, classes):\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    benign_idx = classes.index('benign')\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        scores = get_anomaly_score(netG, netE, netD, images, lambda_)\n",
    "        \n",
    "        # Labels: 0 for benign, 1 for malware (anomaly)\n",
    "        binary_labels = (labels != benign_idx).int()\n",
    "        \n",
    "        all_scores.append(scores.cpu().numpy())\n",
    "        all_labels.append(binary_labels.numpy())\n",
    "        \n",
    "    all_scores = np.concatenate(all_scores)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    fpr, tpr, _ = metrics.roc_curve(all_labels, all_scores)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(f\">> Eval AUC: {auc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_loader, test_loader, classes = get_dataloaders(args.image_size, args.batch_size)\n",
    "    \n",
    "    LATENT_SIZE = 128\n",
    "    CHANNELS = 3\n",
    "    IMG_SIZE = 512\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "    # Instantiate models\n",
    "    netG = Generator(LATENT_SIZE, CHANNELS, upsample_first=False, bn_type='batch')\n",
    "    netE = Encoder(IMG_SIZE, LATENT_SIZE, bn_type='instance')\n",
    "    netD = Discriminator(IMG_SIZE, LATENT_SIZE, bn_type='layer')\n",
    "\n",
    "    optGE = optim.Adam(list(netG.parameters()) + list(netE.parameters()), \n",
    "                       lr=args.lr, betas=(float(args.ge_beta1), float(args.ge_beta2) ))\n",
    "    optD = optim.Adam(netD.parameters(), lr=args.lr, betas=(args.d_beta1, args.d_beta2))\n",
    "\n",
    "    history = {'d_loss': [], 'ge_loss': [], 'auc': []}\n",
    "    for epoch in args.epoch:\n",
    "        netG.train(); netE.train(); netD.train()\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "        \n",
    "        for i, (images, _) in enumerate(pbar):\n",
    "            z = torch.randn(batch_size, args.latent_size).to(device)    \n",
    "            \n",
    "            generated_image = netG(z).detach()\n",
    "            generated_latent = netE(images).detach()\n",
    "            \n",
    "            reconstructed_image = netE(generated_latent).detach()\n",
    "            reconstructed_latent = netG(generated_image).detach()\n",
    "            \n",
    "            # Model Update\n",
    "            if i % args.d_iter == 0:\n",
    "                optD.zero_grad()\n",
    "                real_score = netD(images, generated_latent).detach()\n",
    "                fake_score = netD(generated_image, latent).detach()\n",
    "                \n",
    "                d_loss = (fake_score - real_score).mean();\n",
    "                \n",
    "                gradient_penalty_loss = gradient_penalty(discriminator,\n",
    "                                                         images, generated_images,\n",
    "                                                         latent, generated_latent, device)\n",
    "                discriminator_total_loss = d_loss + gp_weight * gradient_penalty_loss        \n",
    "                discriminator_total_loss.backward()\n",
    "                optD.step()\n",
    "            else:\n",
    "                optGE.zero_grad()\n",
    "                generator_encoder_loss = (real_score - fake_score).mean() # L_E,G\n",
    "                \n",
    "                images_reconstruction_loss = (l1(images, reconstructed_images)).mean()  # L_R\n",
    "                latent_reconstruction_loss = (l1(latent, reconstructed_latent)).mean()  # L_R'\n",
    "                consistency_loss = images_reconstruction_loss + latent_reconstruction_loss  # L_C\n",
    "                \n",
    "                generator_encoder_total_loss = (1 - alpha) * generator_encoder_loss + alpha * consistency_loss  # L*_E,G\n",
    "                ge_total_loss.backward()\n",
    "                optGE.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                history['d_loss'].append(d_total_loss.item())\n",
    "                history['ge_loss'].append(ge_total_loss.item())\n",
    "\n",
    "            pbar.set_postfix({\"D\": f\"{d_total_loss.item():.3f}\", \"GE\": f\"{ge_total_loss.item():.3f}\"})\n",
    "\n",
    "        save_reconstruction_grid(images, netE, netG, epoch, device)\n",
    "        plot_loss_curves(history)\n",
    "        \n",
    "        auc = evaluate(netG, netE, netD, test_loader, device, args.lambda_, classes)\n",
    "        history['auc'].append(auc)\n",
    "        print(f\"Epoch {epoch} | AUC: {auc:.4f}\")\n",
    "\n",
    "        torch.save({\n",
    "            'generator': generator.state_dict(),\n",
    "            'encoder': encoder.state_dict(),\n",
    "            'discriminator': discriminator.state_dict(),\n",
    "            'config': config\n",
    "        }, 'final_model.pth')\n",
    "\n",
    "        pd.DataFrame(history).to_csv('final_training_log.csv', index=False)\n",
    "        print(\"Training completed!\")\n",
    "\n",
    "            \n",
    "def main():    \n",
    "    class Args:\n",
    "        image_size = 512\n",
    "        batch_size = 32\n",
    "        latent_size = 128\n",
    "        channels = 3\n",
    "        lr = 1e-4\n",
    "        ge_beta1, ge_beta2 = 0.0, 0.1\n",
    "        d_beta1, d_beta2 = 0.0, 0.9\n",
    "        gp_weight = 10\n",
    "        alpha = 1e-5\n",
    "        d_iter = 1 # Update GE every d_iter steps\n",
    "        epochs = 50\n",
    "        lambda_ = 0.1 # Weight for feature distance in scoring\n",
    "        \n",
    "        train(Args())\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
